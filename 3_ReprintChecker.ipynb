{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516a3df-a773-42bd-9bc4-5ae6bb1f33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b16cdc-e590-4cb6-803b-566012475be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= CONFIG =========\n",
    "\n",
    "FILES = [\n",
    "    \"./Texts/NewsArticles.txt\",\n",
    "    \"./Texts/MoreNewsArticles.txt\"\n",
    "    #\"../Texts/...,\n",
    "]\n",
    "\n",
    "SIMILARITY_THRESHOLD = 0.80   # try 0.85 if you want fuzzier matches, 90 for stricter matches\n",
    "MIN_CHARS = 400               # ignore very short bodies\n",
    "TOP_K = 200                   # max number of matches to display (None = all)\n",
    "\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07861190-9e47-4f21-8695-ac19039422b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HASH_SPLIT_RE = re.compile(r\"(?m)^\\s*#{4,}\\s*$\")\n",
    "TROVE_URL_RE = re.compile(\n",
    "    r\"https?://nla\\.gov\\.au/nla\\.news-article\\d+(?:[/?]\\S*)?\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class Article:\n",
    "    source_file: str\n",
    "    index_in_file: int\n",
    "    trove_url: Optional[str]\n",
    "    citation_line: Optional[str]\n",
    "    body_norm: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e356c15-28e9-454d-a1c9-075ffb4dfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_articles(text: str) -> List[str]:\n",
    "    parts = HASH_SPLIT_RE.split(text)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "\n",
    "def extract_citation_and_body(block: str):\n",
    "    lines = block.splitlines()\n",
    "    citation = None\n",
    "    body_start = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip():\n",
    "            citation = line.strip()\n",
    "            body_start = i + 1\n",
    "            break\n",
    "\n",
    "    body = \"\\n\".join(lines[body_start:]).strip()\n",
    "    return citation, body\n",
    "\n",
    "\n",
    "def normalise_body(body: str) -> str:\n",
    "    if not body:\n",
    "        return \"\"\n",
    "\n",
    "    body = body.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # join hyphenated line wraps\n",
    "    body = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", body)\n",
    "\n",
    "    # collapse newlines into spaces\n",
    "    body = re.sub(r\"\\n+\", \" \", body)\n",
    "\n",
    "    # lowercase\n",
    "    body = body.lower()\n",
    "\n",
    "    # remove most punctuation\n",
    "    body = re.sub(r\"[“”\\\".,;:!?()\\[\\]{}<>]\", \" \", body)\n",
    "\n",
    "    # collapse whitespace\n",
    "    body = re.sub(r\"\\s+\", \" \", body).strip()\n",
    "\n",
    "    return body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e66bbe-7dac-44ed-838c-b600a6eec314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles(files: List[str]) -> List[Article]:\n",
    "    articles = []\n",
    "\n",
    "    for path in files:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        blocks = split_articles(text)\n",
    "\n",
    "        for i, block in enumerate(blocks, start=1):\n",
    "            citation, body = extract_citation_and_body(block)\n",
    "            url_match = TROVE_URL_RE.search(block)\n",
    "            url = url_match.group(0) if url_match else None\n",
    "\n",
    "            body_norm = normalise_body(body)\n",
    "\n",
    "            articles.append(\n",
    "                Article(\n",
    "                    source_file=os.path.basename(path),\n",
    "                    index_in_file=i,\n",
    "                    trove_url=url,\n",
    "                    citation_line=citation,\n",
    "                    body_norm=body_norm\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "\n",
    "articles = load_articles(FILES)\n",
    "\n",
    "print(f\"Loaded {len(articles)} article blocks.\")\n",
    "print(f\"Using {sum(len(a.body_norm) >= MIN_CHARS for a in articles)} bodies ≥ {MIN_CHARS} chars.\")\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(a.source_file for a in articles)\n",
    "print(\"Articles per file:\")\n",
    "for fname, n in counts.items():\n",
    "    print(f\"  {fname}: {n}\")\n",
    "print(f\"Total articles: {len(articles)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff3223-8c6e-417c-bc76-aaf7d787e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_articles(\n",
    "    articles: List[Article],\n",
    "    threshold: float,\n",
    "    min_chars: int\n",
    "):\n",
    "    idx_map = [i for i, a in enumerate(articles) if len(a.body_norm) >= min_chars]\n",
    "    texts = [articles[i].body_norm for i in idx_map]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(5, 5),\n",
    "        min_df=1\n",
    "    )\n",
    "\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    S = cosine_similarity(X)\n",
    "\n",
    "    matches = []\n",
    "    n = len(idx_map)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            score = float(S[i, j])\n",
    "            if score >= threshold:\n",
    "                matches.append((score, idx_map[i], idx_map[j]))\n",
    "\n",
    "    matches.sort(reverse=True, key=lambda x: x[0])\n",
    "    return matches\n",
    "\n",
    "\n",
    "matches = find_similar_articles(\n",
    "    articles,\n",
    "    SIMILARITY_THRESHOLD,\n",
    "    MIN_CHARS\n",
    ")\n",
    "\n",
    "print(f\"Found {len(matches)} matches ≥ {SIMILARITY_THRESHOLD}.\")\n",
    "if matches:\n",
    "    print(f\"Found {len(matches)} matches ≥ {SIMILARITY_THRESHOLD}.\")\n",
    "else:\n",
    "    print(f\"No matches found ≥ {SIMILARITY_THRESHOLD}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a0922-6115-4bea-ace8-b012444b6859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_match(score, a: Article, b: Article, preview=300):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"SIMILARITY: {score:.3f}\")\n",
    "    print(f\"A: {a.source_file}  [#{a.index_in_file}]\")\n",
    "    print(f\"   URL: {a.trove_url}\")\n",
    "    print(f\"   Citation: {a.citation_line}\")\n",
    "    print(f\"B: {b.source_file}  [#{b.index_in_file}]\")\n",
    "    print(f\"   URL: {b.trove_url}\")\n",
    "    print(f\"   Citation: {b.citation_line}\")\n",
    "    print(\"-\" * 100)\n",
    "    print(\"A preview:\", a.body_norm[:preview], \"…\")\n",
    "    print(\"B preview:\", b.body_norm[:preview], \"…\")\n",
    "    print()\n",
    "\n",
    "\n",
    "for score, i, j in matches[:TOP_K or None]:\n",
    "    show_match(score, articles[i], articles[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a55692-68bf-438f-8e5d-b55857094b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8f331-db60-4bdd-aa1f-9cc5daccf8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e9e96-d6c6-4269-9d11-addf8dcf4325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
